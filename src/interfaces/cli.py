#!/usr/bin/env python3
"""
Enhanced CLI for the Local RAG System
Modern, user-friendly command-line interface with rich features
"""

import os
import sys
import time
from pathlib import Path
from typing import Optional

from src.core.processing.document_processor import DocumentProcessor

from .rag_pipeline_db import RAGPipelineDB, format_answer_db, format_results_db
from .retrieval_db import DatabaseRetriever

# Note: This script must be run as a module: python -m src.app


try:
    from .cache.redis_cache import RedisCache
except ImportError:
    RedisCache = None


class RAGCLI:
    """Enhanced CLI for Local RAG System"""

    def __init__(self):
        self.retriever = None
        self.rag_pipeline = None
        self.processor = None
        self.cache = None

        # Language display names
        self.lang_names = {
            "en": "ğŸ‡ºğŸ‡¸ English",
            "de": "ğŸ‡©ğŸ‡ª German",
            "fr": "ğŸ‡«ğŸ‡· French",
            "es": "ğŸ‡ªğŸ‡¸ Spanish",
            "it": "ğŸ‡®ğŸ‡¹ Italian",
            "pt": "ğŸ‡µğŸ‡¹ Portuguese",
            "nl": "ğŸ‡³ğŸ‡± Dutch",
            "sv": "ğŸ‡¸ğŸ‡ª Swedish",
            "pl": "ğŸ‡µğŸ‡± Polish",
            "zh": "ğŸ‡¨ğŸ‡³ Chinese",
            "ja": "ğŸ‡¯ğŸ‡µ Japanese",
            "ko": "ğŸ‡°ğŸ‡· Korean",
        }

    def print_header(self):
        """Print application header"""
        print("\n" + "=" * 70)
        print("ğŸ¤– LOCAL RAG SYSTEM - Command Line Interface")
        print("=" * 70)
        print("ğŸ” Intelligent document search and AI-powered Q&A")
        print("ğŸŒ 12-language multilingual support with smart detection")
        print("âš¡ Redis caching for lightning-fast responses")
        print("=" * 70)

    def print_menu(self):
        """Print main menu"""
        print("\nğŸ“‹ Available Modes:")
        print("  1. ğŸ¯ Smart Search      - Intelligent search with topic relevance boosting")
        print("  2. ğŸ¤– Full RAG Mode     - AI-powered answers (requires Ollama)")
        print("  3. ğŸ“ Process Documents - Batch process existing files")
        print("  4. ğŸ“Š System Status     - Show system health and metrics")
        print("  5. âš™ï¸  Settings         - Configure system parameters")
        print("  6. ğŸ†˜ Help             - Show detailed help")
        print("  0. ğŸšª Exit             - Quit the application")
        print()

    def initialize_components(self):
        """Initialize system components with error handling"""
        try:
            if not self.retriever:
                print("ğŸ”§ Initializing retriever...")
                self.retriever = DatabaseRetriever()
                print("âœ… Retriever ready")

            if not self.processor:
                print("ğŸ”§ Initializing document processor...")
                self.processor = DocumentProcessor()
                print("âœ… Document processor ready")

            if RedisCache:
                try:
                    self.cache = RedisCache()
                    print("âœ… Redis cache connected")
                except Exception:
                    print("âš ï¸  Redis cache unavailable (continuing without cache)")

        except Exception as e:
            print(f"âŒ Error initializing components: {e}")
            return False
        return True

    def topic_aware_mode(self):
        """Interactive smart search mode with topic relevance boosting"""
        if not self.initialize_components():
            return

        print("\n" + "=" * 50)
        print("ğŸ¯ SMART SEARCH MODE")
        print("=" * 50)
        print("Intelligent search that boosts results based on document topic relevance")
        print("Documents with matching topics get higher relevance scores")
        print("Type 'quit' or 'exit' to return to main menu")
        print("Type 'help' for commands")
        print("-" * 50)

        while True:
            try:
                query = input("\nğŸ¯ Query: ").strip()

                if query.lower() in ["quit", "exit", "q"]:
                    break
                elif query.lower() == "help":
                    self.show_topic_aware_help()
                    continue
                elif not query:
                    continue

                print("â³ Searching with topic awareness...")
                start_time = time.time()
                if self.retriever:
                    results = self.retriever.retrieve_with_topic_boost(query, top_k=3)
                else:
                    print("âŒ Retriever not initialized")
                    continue
                search_time = time.time() - start_time

                print(".2f")
                print(format_results_db(results))

                if results:
                    print(f"\nğŸ“Š Found {len(results)} relevant document chunks")
                    # Show topic boost information
                    boosted_count = sum(1 for r in results if r.get("topic_boost", 0) > 0)
                    if boosted_count > 0:
                        print(f"ğŸ¯ {boosted_count} results boosted by topic relevance")

            except KeyboardInterrupt:
                print("\nğŸ‘‹ Returning to main menu...")
                break
            except Exception as e:
                print(f"âŒ Error during search: {e}")

    def rag_mode(self):
        """Interactive RAG mode with AI generation"""
        print("\n" + "=" * 50)
        print("ğŸ¤– RAG MODE - AI-Powered Answers")
        print("=" * 50)

        # Initialize RAG pipeline
        if not self.rag_pipeline:
            try:
                print("ğŸ”§ Initializing RAG pipeline...")
                self.rag_pipeline = RAGPipelineDB()
                print("âœ… RAG pipeline ready")
            except Exception as e:
                print(f"âŒ Failed to initialize RAG pipeline: {e}")
                print("ğŸ’¡ Make sure Ollama is running: ollama serve")
                print("ğŸ’¡ Pull a model: ollama pull llama2")
                return

        print("Ask questions in any language - AI will respond accordingly")
        print("Type 'quit' or 'exit' to return to main menu")
        print("Type 'help' for commands")
        print("-" * 50)

        while True:
            try:
                question = input("\nâ“ Question: ").strip()

                if question.lower() in ["quit", "exit", "q"]:
                    break
                elif question.lower() == "help":
                    self.show_rag_help()
                    continue
                elif not question:
                    continue

                print("â³ Thinking...")
                start_time = time.time()

                result = self.rag_pipeline.query(question)
                response_time = time.time() - start_time

                # Show language detection
                query_lang = result.get("query_language", "unknown")
                if query_lang != "unknown":
                    lang_display = self.lang_names.get(query_lang, f"ğŸŒ {query_lang.upper()}")
                    print(f"   {lang_display}")

                print(".2f")
                print(format_answer_db(result["answer"]))

                # Show source documents
                if "retrieved_documents" in result and result["retrieved_documents"]:
                    print("\nğŸ“š Source Documents Used:")
                    doc_sources = {}
                    for doc in result["retrieved_documents"]:
                        doc_info = doc.get("document", {})
                        filename = doc_info.get("filename", "Unknown")
                        if filename not in doc_sources:
                            doc_sources[filename] = {"count": 0, "score": 0}
                        doc_sources[filename]["count"] += 1
                        doc_sources[filename]["score"] = max(
                            doc_sources[filename]["score"], doc.get("score", 0)
                        )

                    for i, (filename, info) in enumerate(doc_sources.items(), 1):
                        print(
                            f"  {i}. ğŸ“„ {filename} (chunks: {info['count']}, relevance: {info['score']:.3f})"
                        )

            except KeyboardInterrupt:
                print("\nğŸ‘‹ Returning to main menu...")
                break
            except Exception as e:
                print(f"âŒ Error during query: {e}")

    def process_documents(self):
        """Batch document processing"""
        if not self.initialize_components():
            return

        print("\n" + "=" * 50)
        print("ğŸ“ DOCUMENT PROCESSING")
        print("=" * 50)

        try:
            print("ğŸ”„ Processing existing documents...")
            print("This may take several minutes depending on document count...")

            start_time = time.time()
            if self.processor:
                self.processor.process_existing_documents()
            else:
                print("âŒ Document processor not initialized")
                return
            process_time = time.time() - start_time

            print(".1f")
        except Exception as e:
            print(f"âŒ Error processing documents: {e}")

    def show_system_status(self):
        """Show system health and metrics"""
        print("\n" + "=" * 50)
        print("ğŸ“Š SYSTEM STATUS")
        print("=" * 50)

        # Initialize components if not already done
        if not hasattr(self, "cache") or self.cache is None:
            self.initialize_components()

        # Database status
        try:
            from sqlalchemy import func

            from .database.models import Document, DocumentChunk, SessionLocal

            db = SessionLocal()

            # Get counts with optimized query
            result = (
                db.query(
                    func.count(Document.id).label("doc_count"),
                    func.count(DocumentChunk.id).label("chunk_count"),
                )
                .outerjoin(DocumentChunk)
                .first()
            )

            doc_count = result.doc_count if result else 0
            chunk_count = result.chunk_count if result else 0

            print("ğŸ—„ï¸  Database Status:")
            print(f"   ğŸ“„ Documents: {doc_count}")
            print(f"   ğŸ“¦ Chunks: {chunk_count}")
            print("   âœ… Connected")
            db.close()
        except Exception as e:
            print(f"   âŒ Database: {e}")

        # Elasticsearch status
        try:
            from elasticsearch import Elasticsearch

            es = Elasticsearch(
                hosts=[{"host": "localhost", "port": 9200, "scheme": "http"}],
                verify_certs=False,
            )
            if es.ping():
                print("ğŸ” Elasticsearch: âœ… Connected")
            else:
                print("ğŸ” Elasticsearch: âŒ Not responding")
        except Exception:
            print("ğŸ” Elasticsearch: âŒ Not available")

        # Redis cache status
        if self.cache:
            try:
                stats = self.cache.get_stats()
                print("âš¡ Redis Cache:")
                print(f"   ğŸ“Š Keys: {stats.get('total_keys', 0)}")
                print(f"   ğŸ’¾ Memory: {stats.get('memory_used', 'unknown')}")
                print(".1f")
                print("   âœ… Connected")
            except Exception:
                print("âš¡ Redis Cache: âŒ Error")
        else:
            print("âš¡ Redis Cache: âŒ Not available")

        # Batch processing status
        try:
            from .retrieval_db import DatabaseRetriever

            temp_retriever = DatabaseRetriever()
            batch_stats = temp_retriever.get_batch_stats()
            if batch_stats:
                device = batch_stats.get("device", "unknown").upper()
                if device == "MPS":
                    device_icon = "ğŸ"
                elif device == "CUDA":
                    device_icon = "ğŸ–¥ï¸"
                else:
                    device_icon = "ğŸ’»"

                print(f"ğŸš€ Batch Processing: âœ… Active ({device_icon} {device})")
                total_queries = batch_stats.get("total_queries", 0)
                if total_queries > 0:
                    avg_time = batch_stats.get("avg_processing_time", 0)
                    gpu_util = batch_stats.get("gpu_utilization", 0)
                    print(f"   ğŸ“Š Processed: {total_queries} queries")
                    print(f"   â±ï¸  Avg time: {avg_time:.3f}s")
                    print(f"   ğŸ¯ GPU util: {gpu_util:.1%}")
                else:
                    print("ğŸš€ Batch Processing: âœ… Available (not yet used)")
            else:
                print("ğŸš€ Batch Processing: âŒ Not available")
        except Exception as e:
            print(f"ğŸš€ Batch Processing: âŒ Error ({e})")

        # Ollama status
        try:
            import requests

            response = requests.get("http://localhost:11434/api/tags", timeout=2)
            if response.status_code == 200:
                models = response.json().get("models", [])
                model_names = [m["name"] for m in models]
                print("ğŸ¤– Ollama Status:")
                print(
                    f"   ğŸ“‹ Available models: {', '.join(model_names) if model_names else 'None'}"
                )
                print("   âœ… Connected")
            else:
                print("ğŸ¤– Ollama: âŒ Not responding")
        except Exception:
            print("ğŸ¤– Ollama: âŒ Not available")

        print("\nğŸ’¡ Tip: Visit the web interface for detailed analytics!")

    def show_settings(self):
        """Show and allow configuration of system settings"""
        print("\n" + "=" * 50)
        print("âš™ï¸  SYSTEM SETTINGS")
        print("=" * 50)

        print("Current configuration:")
        print("ğŸ“Š Retrieval Settings:")
        print("   ğŸ”¢ Top-K results: 3 (configurable in web interface)")
        print("   ğŸ“ Chunk size: 1000 characters")
        print("   ğŸ”€ Overlap: 200 characters")

        print("\nğŸ¤– Generation Settings:")
        print("   ğŸ§  Model: llama2 (or qwen2 for better multilingual)")
        print("   ğŸŒ¡ï¸  Temperature: 0.7")
        print("   ğŸ“ Max tokens: 500")

        print("\nâš¡ Performance Settings:")
        print("   ğŸš€ Batch processing: Enabled")
        print("   ğŸ”„ Parallel workers: 4")
        print("   ğŸ’¾ Memory limit: 500MB")

        print("\nğŸ’¡ Configure advanced settings via the web interface (Settings page)")

    def show_help(self):
        """Show detailed help information"""
        print("\n" + "=" * 70)
        print("ğŸ†˜ HELP - Local RAG System CLI")
        print("=" * 70)

        print(
            """
MODES:
   1. Smart Search        - Intelligent search with topic relevance boosting
   2. RAG Mode            - AI-powered answers with source citations
   3. Process Documents   - Batch process and index documents
   4. System Status       - Health check and system metrics
   5. Settings            - View current configuration
   6. Help                - This help screen

FEATURES:
  ğŸŒ Multilingual      - Automatic language detection (12 languages)
  âš¡ Redis Caching      - 172.5x speedup for repeated queries
  ğŸ“Š Source Citations  - Documents used for answers are listed
  ğŸ”„ Auto-initialization- System sets up automatically
  ğŸ“ˆ Performance Monitoring- Query timing and metrics

LANGUAGES SUPPORTED:
  ğŸ‡ºğŸ‡¸ English, ğŸ‡©ğŸ‡ª German, ğŸ‡«ğŸ‡· French, ğŸ‡ªğŸ‡¸ Spanish, ğŸ‡®ğŸ‡¹ Italian
  ğŸ‡µğŸ‡¹ Portuguese, ğŸ‡³ğŸ‡± Dutch, ğŸ‡¸ğŸ‡ª Swedish, ğŸ‡µğŸ‡± Polish
  ğŸ‡¨ğŸ‡³ Chinese, ğŸ‡¯ğŸ‡µ Japanese, ğŸ‡°ğŸ‡· Korean

QUICK START:
    1. Run: python -m src.app (âš ï¸ MUST use module execution)
    2. Choose mode 4 to check system status
    3. Choose mode 3 to process documents
    4. Choose mode 2 for AI answers (requires Ollama)
    5. Choose mode 1 for intelligent document search!

WEB INTERFACE:
  Run: streamlit run web_interface/app.py
  Features: Document upload, analytics dashboard, settings

TROUBLESHOOTING:
  â€¢ Database issues: Check Docker containers are running
  â€¢ Ollama errors: Run 'ollama serve' and pull models
  â€¢ Slow responses: Reduce chunk size or k-value in settings
  â€¢ Memory issues: Use smaller models or reduce batch size
        """
        )

    def show_topic_aware_help(self):
        """Show help for smart search mode"""
        print(
            """
ğŸ¯ SMART SEARCH COMMANDS:
   â€¢ Type any question to search with intelligent topic relevance boosting
   â€¢ 'quit' or 'exit' - Return to main menu
   â€¢ 'help' - Show this help

ğŸ¯ INTELLIGENT SEARCH:
   â€¢ Uses AI-extracted document topics for relevance boosting
   â€¢ Documents with matching topics get higher relevance scores
   â€¢ Combines semantic search with topic awareness

ğŸ’¡ TIPS:
   â€¢ Works best with AI-enriched documents (processed with topic extraction)
   â€¢ Try specific topic-related queries for best results
   â€¢ Results show topic boost indicators for enhanced relevance
        """
        )

    def show_rag_help(self):
        """Show help for RAG mode"""
        print(
            """
ğŸ¤– RAG MODE COMMANDS:
   â€¢ Type any question for AI-powered answers
   â€¢ 'quit' or 'exit' - Return to main menu
   â€¢ 'help' - Show this help

ğŸŒ MULTILINGUAL SUPPORT:
   â€¢ Ask questions in any supported language
   â€¢ AI responds in the same language
   â€¢ Language detection happens automatically

ğŸ“š SOURCE CITATIONS:
   â€¢ Documents used are listed with relevance scores
   â€¢ Multiple chunks from same document are grouped
   â€¢ Higher scores = more relevant information
        """
        )

    def run(self):
        """Main application loop"""
        self.print_header()

        while True:
            self.print_menu()

            try:
                choice = input("Choose mode (0-6): ").strip()

                if choice == "0":
                    print("\nğŸ‘‹ Thank you for using Local RAG System!")
                    break
                elif choice == "1":
                    self.topic_aware_mode()
                elif choice == "2":
                    self.rag_mode()
                elif choice == "3":
                    self.process_documents()
                elif choice == "4":
                    self.show_system_status()
                elif choice == "5":
                    self.show_settings()
                elif choice == "6":
                    self.show_help()
                else:
                    print("âŒ Invalid choice. Please enter 0-6.")

            except KeyboardInterrupt:
                print("\nğŸ‘‹ Thank you for using Local RAG System!")
                break
            except Exception as e:
                print(f"âŒ Unexpected error: {e}")


def main():
    """Main entry point"""
    try:
        cli = RAGCLI()
        cli.run()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Goodbye!")
    except Exception as e:
        print(f"âŒ Fatal error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
