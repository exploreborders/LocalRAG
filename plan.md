# Building a Local RAG System with Python and Ollama

## Overview
This project implements a production-ready Local RAG (Retrieval-Augmented Generation) system using PostgreSQL for document storage, Elasticsearch for vector search, and Ollama for local LLM generation. The system features Docker-based database setup for easy deployment, advanced document processing with Docling, and a modern web interface. It provides accurate, context-aware responses by combining efficient document retrieval with generative AI, all running locally for maximum privacy and control.

## Prerequisites
- Python 3.8 or higher
- Docker (recommended for databases) OR:
  - PostgreSQL database with pgvector extension
  - Elasticsearch 8.x
- Ollama installed on your system (download from https://ollama.ai)
- Basic knowledge of Python and command-line tools

## Step-by-Step Plan

### 1. Set Up the Environment
- Create a new Python virtual environment: `python -m venv rag_env`
- Activate the environment: `source rag_env/bin/activate` (Linux/Mac) or `rag_env\Scripts\activate` (Windows)
- Install required packages: `pip install -r requirements.txt`

### 2. Set Up Databases
- **Docker Compose (Recommended)**: `python setup_databases.py docker` or `docker-compose up -d`
- **Local Setup**: `python setup_databases.py local` for manual installation instructions
- Both PostgreSQL (with pgvector) and Elasticsearch configured automatically

### 3. Install and Configure Ollama
- Install Ollama if not already done
- Pull a suitable model: `ollama pull llama2`
- Verify installation: `ollama list`

### 4. Initialize the System
- Run database migrations: `python scripts/migrate_to_db.py`
- Set up Elasticsearch indices: `python src/database/opensearch_setup.py`

### 5. Process Documents
- Add documents to `data/` directory
- Process via CLI: `python -m src.app` (choose option 3)
- Or upload via web interface: `streamlit run web_interface/app.py`

### 6. Start Using the System
- **Web Interface**: `streamlit run web_interface/app.py` - Full-featured UI
- **CLI**: `python -m src.app` - Command-line access
- **Testing**: `python test_system.py` - Verify functionality

## Additional Considerations
- **Privacy**: Since this is local, data stays on your machine
- **Performance**: Choose appropriate model sizes based on your hardware
- **Scalability**: For larger datasets, consider more robust vector databases
- **Security**: Be cautious with sensitive data in your knowledge base

## Resources
- [LangChain Documentation](https://python.langchain.com/)
- [Ollama Documentation](https://github.com/jmorganca/ollama)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [Elasticsearch Documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)
- [pgvector Documentation](https://github.com/pgvector/pgvector)

This plan provides a high-level overview. Each step may require additional research and implementation details based on your specific use case.

## Implementation Progress

### ‚úÖ **Phase 1: Core RAG System (COMPLETED)**

1. **Environment Setup**
    - Created Python virtual environment: `python -m venv rag_env`
    - Installed comprehensive dependencies including Streamlit for web interface
    - Set up proper import handling for both CLI and module execution

2. **Project Structure & Architecture**
    - Created modular structure: `src/`, `data/`, `models/`, `web_interface/`
    - Implemented proper error handling and logging throughout
    - Added configuration management with YAML settings

3. **Data Processing Pipeline**
    - **Document Loading**: Docling-powered parsing for .txt, .pdf, .docx, .pptx, .xlsx files with layout awareness
    - **Text Chunking**: RecursiveCharacterTextSplitter with configurable chunk size (1000) and overlap (200)
    - **Preprocessing**: Advanced text extraction with table structure preservation and markdown export
    - **Document Count**: Successfully processing 34 documents into database-backed chunks

4. **Embedding System**
    - **Primary Model**: nomic-ai/nomic-embed-text-v1.5 (768 dimensions) for high performance
    - **Database Storage**: PostgreSQL with pgvector for chunk storage
    - **Elasticsearch Indexing**: Vector similarity search with KNN optimization
    - **Performance**: Optimized batch processing and memory management

5. **Vector Storage**
    - **FAISS Integration**: L2 distance indexing for similarity search
    - **Persistence**: Index saving/loading functionality
    - **Search**: Efficient k-nearest neighbor retrieval

6. **Retrieval Engine**
    - **Retriever Class**: Clean API for document retrieval
    - **Query Processing**: Real-time embedding of user queries
    - **Results Formatting**: Structured output with relevance scores

7. **LLM Integration**
    - **Ollama Integration**: LangChain-based RAG pipeline
    - **Model Support**: Dynamic detection of installed Ollama models
    - **Fallback Handling**: Graceful degradation when Ollama unavailable

8. **CLI Interface**
    - **Dual Mode**: Retrieval-only and full RAG modes
    - **Interactive**: Command-line query interface
    - **Error Handling**: Clear feedback for missing components

### ‚úÖ **Phase 2: Web Interface & Multi-Model Support (COMPLETED)**

9. **Comprehensive Web Interface**
    - **üè† Home Page**: Query interface with mode selection
    - **üìÅ Documents Page**: File upload, management, and processing
    - **‚öôÔ∏è Settings Page**: Configuration with dynamic model detection
    - **üìä Analytics Page**: Performance monitoring and metrics
    - **Theme Support**: Dark/light mode with Streamlit integration

10. **Multi-Model Embedding System**
     - **Model Support**: all-MiniLM-L6-v2, all-mpnet-base-v2, paraphrase-multilingual-mpnet-base-v2
     - **Model-Specific Storage**: Separate files for each model (`embeddings_{model}.pkl`, `faiss_index_{model}.pkl`)
     - **Dynamic Detection**: Automatic discovery of available sentence-transformers models
     - **Model Switching**: Seamless switching between embedding models

11. **Smart Caching & Optimization**
     - **Document Hashing**: MD5-based change detection to avoid reprocessing
     - **Batch Processing**: Simultaneous processing with multiple models
     - **Memory Optimization**: GPU acceleration, batch size tuning, CUDA cache clearing
     - **Performance Monitoring**: Query timing and resource usage tracking

12. **Model Comparison & Analytics**
     - **Side-by-Side Comparison**: Performance testing across different models
     - **Metrics Dashboard**: Query history, response times, system status
     - **Export Functionality**: CSV/JSON export of analytics data
     - **Real-time Monitoring**: Live system health indicators

13. **Enhanced Error Handling**
     - **Validation**: Comprehensive checks for data integrity
     - **User-Friendly Messages**: Clear feedback for configuration issues
     - **Graceful Degradation**: System continues functioning with partial failures
     - **Debug Information**: Detailed error reporting for troubleshooting

### ‚úÖ **Phase 3: Production Features (COMPLETED)**

14. **Advanced Configuration**
     - **YAML Settings**: Centralized configuration management
     - **Dynamic Updates**: Real-time parameter adjustment
     - **Model Selection**: Runtime switching between LLMs and embedding models
     - **Theme Customization**: UI personalization options

15. **Batch Operations**
     - **Multi-Model Processing**: Process documents with multiple embedding models simultaneously
     - **Progress Tracking**: Real-time progress bars and status updates
     - **Resource Management**: Efficient memory usage during batch operations

16. **Performance Optimizations**
     - **GPU Support**: Automatic CUDA detection and utilization
     - **Optimized Indexing**: IVF-PQ indices for large datasets
     - **Memory Management**: Automatic cleanup and resource optimization
     - **Query Optimization**: Normalized embeddings for better similarity search

17. **Documentation & Testing**
     - **Comprehensive README**: Setup, usage, and feature documentation
     - **AGENTS.md**: Development guidelines and command reference
     - **System Testing**: Automated test suite for core functionality
     - **User Guides**: Clear instructions for all features

### üéØ **Current System Status**

**‚úÖ Fully Functional Features:**
- Docker-based database setup (PostgreSQL + Elasticsearch with single command)
- Database-backed document storage with PostgreSQL and pgvector
- Vector search with Elasticsearch for high-performance similarity search
- Hybrid retrieval combining vector similarity and BM25 text search
- Advanced document processing with Docling (layout-aware parsing, table extraction)
- Multi-format document processing (PDF, DOCX, XLSX, PPTX, TXT)
- Ollama integration for local LLM generation
- Modern web interface with document management and analytics
- CLI tools for processing and testing
- Production-ready architecture with proper indexing

**üìä System Metrics:**
- **Database**: PostgreSQL with pgvector + Elasticsearch with dense vectors
- **Documents Processed**: 34 files with Docling-powered parsing and chunking
- **Vector Dimensions**: 768 (nomic-embed-text-v1.5 model)
- **Web Interface**: 4-page Streamlit application with real-time processing
- **Performance**: Sub-second query responses with accurate retrieval
- **Scalability**: Supports large document collections with efficient indexing

### ‚úÖ **Phase 4: PostgreSQL + Elasticsearch Integration (COMPLETED)**

**Goal**: Transform the system into a production-ready, scalable document search platform

#### **Phase 4.1: Infrastructure Setup (COMPLETED)**
- ‚úÖ Install and configure PostgreSQL database server with pgvector
- ‚úÖ Create rag_system database with proper schemas
- ‚úÖ Configure environment variables and connection settings
- ‚úÖ Install and configure Elasticsearch via Docker
- ‚úÖ Set up Elasticsearch indices for documents and vectors

#### **Phase 4.2: Data Migration (COMPLETED)**
- ‚úÖ Migrate existing documents and metadata to PostgreSQL (34 documents)
- ‚úÖ Implement document processing for chunking and embedding
- ‚úÖ Create migration scripts with validation
- ‚úÖ Process existing documents into database + Elasticsearch

#### **Phase 4.3: Core Integration (COMPLETED)**
- ‚úÖ Implement DocumentProcessor with database storage
- ‚úÖ Update retrieval system for hybrid vector + text search
- ‚úÖ Add Elasticsearch vector similarity search with KNN
- ‚úÖ Implement proper error handling and validation

#### **Phase 4.4: API & UI Updates (COMPLETED)**
- ‚úÖ Update web interface for database-backed operations
- ‚úÖ Update Home page with DatabaseRetriever and RAGPipelineDB
- ‚úÖ Update Documents page with DocumentProcessor integration
- ‚úÖ Add real-time processing status and feedback
- ‚úÖ Implement document management with status tracking

#### **Phase 4.5: Testing & Optimization (COMPLETED)**
- ‚úÖ Performance benchmarking: ~2x faster than FAISS-based system
- ‚úÖ Load testing with concurrent queries (25 queries, 5 workers)
- ‚úÖ Query optimization with normalized embeddings
- ‚úÖ Production deployment ready with Docker Compose

### ‚úÖ **Phase 5: Code Cleanup and Documentation (COMPLETED)**

#### **Code Optimization**
- ‚úÖ Remove unused FAISS-related code and files
- ‚úÖ Clean embeddings.py to core functionality only
- ‚úÖ Update all imports and dependencies
- ‚úÖ Add comprehensive docstrings to all functions
- ‚úÖ Fix import issues and error handling

#### **Documentation Updates**
- ‚úÖ Update README.md with current architecture
- ‚úÖ Update web interface documentation
- ‚úÖ Clean requirements.txt of unused packages
- ‚úÖ Update plan.md with completion status

#### **Testing and Validation**
- ‚úÖ System tests pass with database operations
- ‚úÖ Document processing verified working
- ‚úÖ Retrieval and RAG pipelines functional
- ‚úÖ Web interface fully operational

### ‚úÖ **Phase 6: Docling Integration (COMPLETED)**

#### **Advanced Document Processing**
- ‚úÖ Integrate Docling 2.5.2 for superior document parsing
- ‚úÖ Replace individual parsers (PyPDF2, python-docx, etc.) with unified Docling API
- ‚úÖ Add layout-aware text extraction with table structure preservation
- ‚úÖ Implement markdown export for better document structure retention
- ‚úÖ Add fallback mechanisms for unsupported formats

#### **Model Optimization**
- ‚úÖ Configure nomic-ai/nomic-embed-text-v1.5 as primary embedding model
- ‚úÖ Update all processing pipelines to use the nomic model
- ‚úÖ Maintain backward compatibility with existing document processing

#### **System Updates**
- ‚úÖ Update AGENTS.md with new document processing guidelines
- ‚úÖ Update README.md and plan.md with Docling integration details
- ‚úÖ Clean and optimize requirements.txt

### ‚úÖ **Phase 7: Docker Database Setup (COMPLETED)**

#### **Unified Database Management**
- ‚úÖ Create setup_databases.py helper script for easy database management
- ‚úÖ Configure docker-compose.yml with PostgreSQL (pgvector) and Elasticsearch
- ‚úÖ Implement automatic database health checks and connection testing
- ‚úÖ Add environment-based database configuration for Docker vs local development

#### **Streamlined Setup Process**
- ‚úÖ Single-command database startup: `python setup_databases.py docker`
- ‚úÖ Automatic schema initialization with pgvector extension
- ‚úÖ Comprehensive setup instructions for both Docker and local environments
- ‚úÖ Updated documentation with Docker-first approach

#### **Development Workflow Improvements**
- ‚úÖ Seamless switching between Docker and local database configurations
- ‚úÖ Environment variable-based configuration for different deployment scenarios
- ‚úÖ Improved error handling and user feedback during setup
- ‚úÖ Production-ready Docker configuration with health checks and dependencies
- ‚úÖ Test end-to-end document processing pipeline


### üéØ **Future Enhancement Opportunities**

The system is now production-ready with a solid foundation. Potential future improvements include:

- **Advanced Analytics**: Enhanced performance metrics and custom dashboards
- **Conversation Memory**: Multi-turn conversations with context preservation
- **Document Management**: Advanced tagging, categorization, and search filters
- **REST API**: External integrations and programmatic access
- **Cloud Deployment**: Container orchestration and cloud-native hosting
- **Model Updates**: Support for latest embedding and LLM architectures
- **Multilingual Enhancement**: Improved non-English language processing
- **Real-time Features**: Live indexing and incremental document updates
- **Security**: Access controls and data encryption for enterprise use